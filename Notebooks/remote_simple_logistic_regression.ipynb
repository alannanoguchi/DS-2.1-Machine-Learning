{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this class, you should be able to...\n",
    "\n",
    "1. Use a logistic regression classifier and understand its use cases\n",
    "1. Compare and contrast logistic regression and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Logistic Regression?\n",
    "\n",
    "- Logistic regression is another type of classifier, which **is different from linear regression** \n",
    "- Logistic regression predicts whether something is True or False, and the plot is an S-curve that goes from 0 to 1 (probability of False to True)\n",
    "- How is it different from SVM?\n",
    "    - SVM **can not** tell us what the _probability_ is of being classified in a given category \n",
    "    - For example, going back to the example we used in our SVM class, if my Serotonin is 3 and my Dopamine is 6, what is the chance that I would be considered happy? 90 percent? 60 percent? etc...\n",
    "- Logistic Regression tell us this information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logistic Regression Video\n",
    "\n",
    "Before we start the video, here are some concepts that are mentioned in the video:\n",
    "\n",
    "- R-Squared (R^2): is a number between 0 to 1, close to one means better model for linear regression (i.e. the closer to one, the better fit the line is)\n",
    "- Multiple Regression: Regression model using 3+ variables\n",
    "\n",
    "Let's watch this video: https://www.youtube.com/watch?v=yIYKR4sgzI8\n",
    "\n",
    "### Optional Viewing\n",
    "Here's the video on Maximum Likelihood that is mentioned in the above video: https://www.youtube.com/watch?v=XepXtl9YKwc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The dataset we use for Logistic Regression\n",
    "\n",
    "- Dataset we will use today: [diabetes.csv](./Datasets/diabetes.csv)\n",
    "- The objective of the dataset is to **diagnostically predict whether or not a patient has diabetes, based on certain diagnostic measurements included in the dataset**\n",
    "- In particular, all patients here are females at least 21 years old of Pima Indian heritage\n",
    "- Labels: \n",
    "    - 1: diabetes\n",
    "    - 0: no diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity: Fit a Logistic Regression Classifier on diabetes.csv \n",
    "**In groups of 3, complete the following steps:**\n",
    "\n",
    "1- Load the dataset: `pd.read_csv('diabetes.csv')`\n",
    "\n",
    "2- Use these features: `feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']`\n",
    "\n",
    "3- Split the data to train and test: `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)`\n",
    "\n",
    "4- Obtain the statistics of `y_test`\n",
    "\n",
    "**Hints:**\n",
    "\n",
    "- make sure to have the following imports: \n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "```\n",
    "- What's `sklearn.model_selection`? [read about it here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pima = pd.read_csv('diabetes.csv')\n",
    "\n",
    "feature_cols = ['Pregnancies', 'Insulin', 'BMI', 'Age']\n",
    "\n",
    "# X is a matrix, access the features we want in feature_cols\n",
    "X = pima[feature_cols]\n",
    "\n",
    "# y is a vector, hence we use dot to access 'label'\n",
    "y = pima['Outcome']\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity: Check the size of y_train and show that it is 75% of the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n",
      "576.0\n",
      "192\n",
      "192.0\n"
     ]
    }
   ],
   "source": [
    "# check the size of y_train\n",
    "\n",
    "print(len(y_train))\n",
    "print(0.75*len(pima))\n",
    "\n",
    "print(len(y_test))\n",
    "print(0.25*len(pima))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity: Build the classifier model with Logistic Regression and produce y_pred from X_test (features from test part)\n",
    "\n",
    "**Hint:** read up on [sklearn's LogisticRegression module](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), specifically the `fit` and `predict` methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# fit model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 0 0 1 1 1 1 0 0 1 1 1 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 1 1 1 1 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0\n",
      " 0 1 0 1 0 0 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 1\n",
      " 0 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.values.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity: How many samples in y_test have diabetes, and how many do not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# create and plot a histogram based on y_test\n",
    "plt.hist(y_test, bins=20)\n",
    "plt.show()\n",
    "\n",
    "# count how many are 0 and 1 (no diabetes, has diabetes)\n",
    "y_test_pd_series = pd.Series(y_test)\n",
    "y_test_pd_series.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Confusion Matrix\n",
    "\n",
    "A **confusion matrix** is a table that is used to describe the performance of a classifier on a set of test data where we know the true vales. Essentially, we use it to check how well our classifier's predicted values matched against the known values of the same data.\n",
    "\n",
    "The confusion matrix itself is a simple 2x2 matrix, but it's important we go over the terminology of each row/column in the matrix:\n",
    "\n",
    "**True Positives (TP):** we correctly predicted a positive outcome (i.e. someone has diabetes, and we correctly predicted it)\n",
    "\n",
    "**True Negatives (TN):** we correctly predicted a negative outcome (i.e. someone does _not_ have diabetes, and we correctly predicted it)\n",
    "\n",
    "**False Positives (FP):** we incorrectly predicted a positive outcome (i.e. someone does _not_ diabetes, and we incorrectly said that they did)\n",
    "\n",
    "**False Negatives (FN):** we incorrectly predicted a negative outcome (i.e. someone has diabetes, and we incorrectly said that they do _not_)\n",
    "\n",
    "![blank confusion matrix](./Images/blank_confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Activity: Write a function that calculates the confusion matrix for the Pima Diabetes dataset\n",
    "\n",
    "- How many 0s (no diabetes) in y_test are predicted correctly as 0 (no diabetes) in y_pred?\n",
    "    - True Positives\n",
    "\n",
    "- How many 0s (no diabetes) in y_test are predicted incorrectly as 1 (diabetes) in y_pred?\n",
    "    - False Positive\n",
    "\n",
    "- How many 1s (diabetes) in y_test are predicted incorrectly as 0 (no diabetes) in y_pred?\n",
    "    - False Negative\n",
    "\n",
    "- How many 1s (diabetes) in y_test are predicted correctly 1 (diabetes) in y_pred?\n",
    "    - True Negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118.  12.]\n",
      " [ 47.  15.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def comp_yt_yp(y_test, y_predict):\n",
    "    # create a blank 2x2 confusion matrix (all 0s)\n",
    "    conf_matrix  = np.zeros((2, 2))\n",
    "    # indices that will create all confusion matrix values\n",
    "    # TP (1,1), TN (0,0), FP (0, 1), FN (1, 0)\n",
    "    for row_index in [0, 1]:\n",
    "        for column_index in [0, 1]:\n",
    "            counter = 0\n",
    "            # iterate through all elements of y_test, y_predict,\n",
    "            # which are all values of either 0 or 1\n",
    "            for (yt_index, yp_index) in zip(y_test, y_predict):\n",
    "                # comparing the elements of y_test and y_predict with each confusion matrix value (TP, TN, FP, FN),\n",
    "                # and if there's a match for the confusion matrix value we're looking at, increment the counter\n",
    "                if (yt_index == row_index) & (yp_index == column_index):\n",
    "                        counter += 1\n",
    "            # Add the total number of elements for the confusion matrix value,\n",
    "            # then look at the next value in the loop\n",
    "            conf_matrix[row_index, column_index] = counter \n",
    "    return conf_matrix\n",
    "\n",
    "# print the result of calculating our confusion matrix\n",
    "print(comp_yt_yp(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Revisit  Confusion Matrix Terminology \n",
    "\n",
    "**True Positives (TP):** we correctly predicted that they do have diabetes: 15\n",
    "\n",
    "**True Negatives (TN):** we correctly predicted that they don't have diabetes: 118\n",
    "\n",
    "**False Positives (FP):** we incorrectly predicted that they do have diabetes (_\"Type I error\"_): 12\n",
    "\n",
    "**False Negatives (FN):** we incorrectly predicted that they don't have diabetes (_\"Type II error\"_): 47\n",
    "\n",
    "<img src=\"Images/confusion_matrix.png\" width=\"500\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Easier way to compute elements of Confusion Matrix using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(confusion)\n",
    "\n",
    "TP = confusion[1, 1]\n",
    "TN = confusion[0, 0]\n",
    "FP = confusion[0, 1]\n",
    "FN = confusion[1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activity: Apply these two methods to Pima Indian Diabetes dataset\n",
    "\n",
    "After `logreg.fit(X_train, y_train)`, call the trained model using:\n",
    "- `logreg.predict(X_test)`\n",
    "- `logreg.predict_proba(X_test)`\n",
    "    \n",
    "Notice the difference in the results, and discuss it with your peers. What does each method do with the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The difference between `.predict()` and `.predict_proba` for logistic reg classifier\n",
    "\n",
    "- [predict](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict) will return a list of 0 and 1 values for a given sample\n",
    "- [predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba) will return a list of lists where each element in the list is a probability estimate: the probability of the element being a 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources:\n",
    "\n",
    "- https://www.ritchieng.com/machine-learning-evaluate-classification-model/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
